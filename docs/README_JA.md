<p align="center">
  <a href="../README.md">ç®€ä½“ä¸­æ–‡</a> Â·
  <a href="README_EN.md">English</a> Â·
  <a href="README_JA.md">æ—¥æœ¬èª</a>
</p>

# åˆ†å­è¨˜è¿°å­ã«åŸºã¥ã Huggins ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆchiï¼‰ã® QSAR äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

> ã“ã®ç‰ˆã¯ AI ç¿»è¨³ã§ã™ã€‚è¡¨ç¾ã«è»½å¾®ãªä¸è‡ªç„¶ã•ãŒå«ã¾ã‚Œã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
>
> æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€**QSARï¼ˆå®šé‡çš„æ§‹é€ æ´»æ€§ç›¸é–¢ï¼‰** æ‰‹æ³•ã‚’ç”¨ã„ã€åˆ†å­è¨˜è¿°å­ã¨æ©Ÿæ¢°å­¦ç¿’ / æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã€é«˜åˆ†å­-æº¶åª’ç³»ã® **Huggins ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÏ‡ï¼‰** ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚

---

## ğŸ“‹ ç›®æ¬¡

- [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦](#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦)
- [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ](#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ)
- [Step 5: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](#step-5-ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)
- [Step 6: ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã¨è§£æ](#step-6-ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã¨è§£æ)
- [ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª¬æ˜](#ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª¬æ˜)
- [ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](#ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯)
- [ä»£è¡¨çš„ãªå‡ºåŠ›å›³](#ä»£è¡¨çš„ãªå‡ºåŠ›å›³)
- [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
- [è©•ä¾¡æŒ‡æ¨™](#è©•ä¾¡æŒ‡æ¨™)

---

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

**Huggins ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÏ‡ï¼‰** ã¯ã€é«˜åˆ†å­-æº¶åª’ç›¸äº’ä½œç”¨ã‚’è¨˜è¿°ã™ã‚‹é‡è¦ãªç†±åŠ›å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚Šã€æ··åˆç³»ã«ãŠã‘ã‚‹æº¶åª’ã¨é«˜åˆ†å­é–“ã®è¦ªå’Œæ€§ã‚’åæ˜ ã—ã¾ã™ã€‚

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ ¸å¿ƒçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š

1. å…ƒã®æ–‡çŒ®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒ–åˆç‰©åã‚’æŠ½å‡ºã—ã€**SMILES** åˆ†å­æ§‹é€ è¡¨ç¾ã«å¤‰æ›ã—ã¾ã™ã€‚
2. è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµ±åˆã—ã¾ã™ï¼ˆæ—§ãƒ‡ãƒ¼ã‚¿ 323ä»¶ + æ–°ãƒ‡ãƒ¼ã‚¿ 1586ä»¶ = **1893ä»¶**ï¼‰ã€‚
3. **RDKit** ã‚’åˆ©ç”¨ã—ã¦ã€å…¨ **ç´„210å€‹** ã®2Dåˆ†å­è¨˜è¿°å­ + æŒ‡ç´‹é¡ä¼¼åº¦ + ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è‡ªå‹•è¨ˆç®—ã—ã€**320æ¬¡å…ƒã®ç‰¹å¾´é‡è¡Œåˆ—** ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
4. **éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆGAï¼‰** ã‚’ä½¿ç”¨ã—ã¦ã€320æ¬¡å…ƒã®ä¸­ã‹ã‚‰æœ€é©ãªç‰¹å¾´é‡ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¾ã™ã€‚
5. æœ€é©ãªç‰¹å¾´é‡ã«åŸºã¥ãã€**AutoTune** ã‚’ä½¿ç”¨ã—ã¦ ML / DNN ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã¨å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚

---

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

```text
Graduation-project/
â”‚
â”œâ”€â”€ è·å–SMILES.py              # Step 1: åŒ–åˆç‰©å â†’ SMILES
â”œâ”€â”€ æ•°æ®å¤„ç†éƒ¨åˆ†ä»£ç .py          # Step 2: Ï‡ å¼ã®è§£æ + æ¸©åº¦å±•é–‹
â”œâ”€â”€ åˆå¹¶æ•°æ®é›†.py               # Step 2.5: æ—§ãƒ‡ãƒ¼ã‚¿ã¨æ–°ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ
â”œâ”€â”€ ç‰¹å¾å·¥ç¨‹.py                 # Step 3: å…¨é‡ RDKit è¨˜è¿°å­æŠ½å‡º (320æ¬¡å…ƒ)
â”œâ”€â”€ é—ä¼ .py                    # Step 4a: éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  (GA) ç²—é¸åˆ¥
â”œâ”€â”€ ç‰¹å¾ç­›é€‰.py                 # Step 4b: RFECV ç²¾é¸åˆ¥
â”œâ”€â”€ feature_config.py           # ç‰¹å¾´é‡è¨­å®šã‚»ãƒ³ã‚¿ãƒ¼ (é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡åˆ—ã®çµ±ä¸€ç®¡ç†)
â”‚
â”œâ”€â”€ DNN_AutoTune.py            # Step 5a: DNN Hyperband è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
â”œâ”€â”€ Sklearn_AutoTune.py        # Step 5b: Sklearn RandomizedSearch è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
â”‚
â”œâ”€â”€ DNN_æ¨¡å‹éªŒè¯.py             # Step 6a: DNN ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼
â”œâ”€â”€ DNNç‰¹å¾è´¡çŒ®åˆ†æ.py          # Step 6c: DNN SHAP ç‰¹å¾´é‡å¯„ä¸åˆ†æ
â”œâ”€â”€ Y_Randomization.py         # Step 6d: Sklearn Y-Randomization æ¤œè¨¼
â”œâ”€â”€ DNN_Y_Randomization.py     # Step 6e: DNN Y-Randomization æ¤œè¨¼
â”‚
â”œâ”€â”€ Huggins.xlsx               # å…ƒãƒ‡ãƒ¼ã‚¿ï¼šåŒ–åˆç‰©å + Huggins ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
â”‚
â”œâ”€â”€ data/                      # ä¸­é–“ãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ smiles_raw.csv
â”‚   â”œâ”€â”€ smiles_cleaned.xlsx
â”‚   â”œâ”€â”€ huggins_preprocessed.xlsx
â”‚   â”œâ”€â”€ 43579_2022_237_MOESM1_ESM.csv  # æ–°è¦å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (1586ä»¶)
â”‚   â”œâ”€â”€ merged_dataset.csv             # çµ±åˆå¾Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (1893ä»¶)
â”‚   â”œâ”€â”€ molecular_features.xlsx        # 320æ¬¡å…ƒç‰¹å¾´é‡è¡Œåˆ—
â”‚   â””â”€â”€ features_optimized.xlsx        # é¸åˆ¥å¾Œç‰¹å¾´é‡ã‚µãƒ–ã‚»ãƒƒãƒˆ
â”‚
â”œâ”€â”€ results/                   # ãƒ¢ãƒ‡ãƒ«ã¨çµæœ
â”‚   â”œâ”€â”€ best_model.keras        # DNN AutoTune æœ€è‰¯ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ best_model_preprocess.pkl # DNN å‰å‡¦ç†å™¨ + æœ€è‰¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ sklearn_model_bundle.pkl # Sklearn çµ±ä¸€ãƒ¢ãƒ‡ãƒ«ãƒãƒ³ãƒ‰ãƒ«
â”‚   â”œâ”€â”€ ga_best_model.pkl      # GA é¸å‡ºæœ€è‰¯ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ ga_selected_features.txt     # GA é¸åˆ¥ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
â”‚   â”œâ”€â”€ ga_evolution_log.csv         # GA é€²åŒ–ãƒ­ã‚°
â”‚   â”œâ”€â”€ sklearn_tuning_summary.csv   # AutoTune æ¢ç´¢ãƒ¬ãƒãƒ¼ãƒˆ
â”‚   â”œâ”€â”€ train_test_split_indices.npz # çµ±ä¸€ train/test åˆ†å‰²ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
â”‚   â”œâ”€â”€ feature_selection.png        # ç‰¹å¾´é‡é¸åˆ¥å¯è¦–åŒ–
â”‚   â””â”€â”€ dnn_loss.png                 # å­¦ç¿’æå¤±æ›²ç·š
â”‚
â”œâ”€â”€ final_results/             # æœ€çµ‚æˆæœç‰©ï¼ˆä¸­é–“ç”Ÿæˆç‰©ã¨åˆ†é›¢ï¼‰
â”‚   â”œâ”€â”€ dnn/
â”‚   â”‚   â”œâ”€â”€ dnn_y_randomization.csv
â”‚   â”‚   â”œâ”€â”€ dnn_y_randomization.png
â”‚   â”‚   â”œâ”€â”€ dnn_y_randomization_summary.txt
â”‚   â”‚   â”œâ”€â”€ dnn_validation_plots.png
â”‚   â”‚   â”œâ”€â”€ dnn_validation_results.csv
â”‚   â”‚   â””â”€â”€ dnn_feature_importance.csv
â”‚   â””â”€â”€ sklearn/
â”‚       â”œâ”€â”€ sklearn_model_bundle.pkl
â”‚       â”œâ”€â”€ fingerprint_model.pkl
â”‚       â”œâ”€â”€ sklearn_tuning_summary.csv
â”‚       â”œâ”€â”€ sklearn_validation_results.xlsx
â”‚       â”œâ”€â”€ sklearn_feature_importance.csv
â”‚       â”œâ”€â”€ sklearn_feature_importance.png
â”‚       â”œâ”€â”€ sklearn_validation_plots.png
â”‚       â”œâ”€â”€ y_randomization.png
â”‚       â”œâ”€â”€ y_randomization.csv
â”‚       â””â”€â”€ sklearn_final_report.txt
â”‚
â”œâ”€â”€ utils/                     # å…±æœ‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â””â”€â”€ data_utils.py           # load_saved_split_indices ç­‰
â”‚
â”œâ”€â”€ requirements.txt           # Python ä¾å­˜ãƒªã‚¹ãƒˆ
â”œâ”€â”€ README.md                  # æœ¬ãƒ•ã‚¡ã‚¤ãƒ«
â”‚
â”œâ”€â”€ æµ‹è¯•/                      # å®Ÿé¨“ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ æ¨¡å‹/                      # éå»ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
â”œâ”€â”€ å‚è€ƒ/                      # å‚è€ƒã‚³ãƒ¼ãƒ‰
â””â”€â”€ åºŸå¼ƒæ–‡ä»¶å­˜æ¡£/               # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿æ—§ãƒ•ã‚¡ã‚¤ãƒ« (Sklearn.py, DNN.py ç­‰)
```

---

## Step 5: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

### Step 5a: DNN Hyperband è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: [`DNN_AutoTune.py`](DNN_AutoTune.py)

Keras Tuner ã® Hyperband ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ã€DNN ã®æœ€é©ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆ1-3å±¤ã€12-64ãƒãƒ¼ãƒ‰ã€å­¦ç¿’ç‡ã€æ­£å‰‡åŒ–ãªã©ï¼‰ã‚’æ¢ç´¢ã—ã¾ã™ã€‚

| è¨­å®šé …ç›® | å€¤ |
|----------|----|
| æ¢ç´¢æˆ¦ç•¥ | Hyperband (Keras Tuner) |
| æ¢ç´¢ç©ºé–“ | 1-3å±¤, 12-64ãƒãƒ¼ãƒ‰, L2æ­£å‰‡åŒ–, Dropout |
| ãƒ‡ãƒ¼ã‚¿åˆ†å‰² | 60% è¨“ç·´ / 20% æ¤œè¨¼ / 20% ãƒ†ã‚¹ãƒˆ |
| æ¨™æº–åŒ– | X ã¨ y ã®ä¸¡æ–¹ã« StandardScaler ã‚’ä½¿ç”¨ |
| å†å­¦ç¿’ | æœ€é©ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç•°ãªã‚‹ã‚·ãƒ¼ãƒ‰ã§8å›å†å­¦ç¿’ |

```bash
# .venv å†…ã® Python (Keras 3 äº’æ›) ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
.venv\Scripts\python.exe DNN_AutoTune.py
```

### Step 5b: Sklearn AutoTuneï¼ˆæ¨å¥¨ï¼‰

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: [`Sklearn_AutoTune.py`](Sklearn_AutoTune.py)

4ã¤ã®ãƒ¢ãƒ‡ãƒ« Ã— 50çµ„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ Ã— 5åˆ†å‰²äº¤å·®æ¤œè¨¼ï¼ˆCVï¼‰ã«ã‚ˆã‚‹è‡ªå‹•æœ€é©åŒ–ï¼š

| ãƒ¢ãƒ‡ãƒ« | æ¢ç´¢æ¬¡å…ƒ |
|--------|---------|
| GradientBoosting | loss, lr, n_estimators, depth, subsample |
| XGBRegressor | lr, n_estimators, depth, reg_alpha/lambda |
| RandomForest | n_estimators, depth, max_features |
| MLPRegressor | hidden layers, activation, alpha, lr |

å®Ÿè¡Œå¾Œã€ä»¥ä¸‹ã‚’è‡ªå‹•çš„ã«å®Œäº†ã—ã¾ã™ï¼š

1. æœ€é©ãƒ¢ãƒ‡ãƒ«æ¢ç´¢ï¼ˆCV é¸å®šï¼‰
2. ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆæ¤œè¨¼ï¼ˆRÂ²/MAE/RMSEã€è¨“ç·´ã«é–¢ä¸ã—ã¦ã„ãªã„ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®ã¿ã‚’ä½¿ç”¨ï¼‰
3. ç‰¹å¾´é‡å¯„ä¸åˆ†æï¼ˆçµ„ã¿è¾¼ã¿é‡è¦åº¦ ã¾ãŸã¯ permutation importanceï¼‰
4. æ¤œè¨¼å¯è¦–åŒ–ï¼ˆå®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤ã€æ®‹å·®åˆ†å¸ƒã€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãªã©4æšã®å›³ï¼‰
5. æœ€çµ‚æˆæœç‰©ã‚’ `final_results/sklearn/` ã«å‡ºåŠ›

```bash
python Sklearn_AutoTune.py
```

---

## Step 6: ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã¨è§£æ

### ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼

| ã‚¹ã‚¯ãƒªãƒ—ãƒˆ | æ©Ÿèƒ½ |
|------------|------|
| [`DNN_æ¨¡å‹éªŒè¯.py`](DNN_æ¨¡å‹éªŒè¯.py) | DNN ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€å…¨ãƒ‡ãƒ¼ã‚¿ã§ RÂ²/MAE/RMSE ã‚’è©•ä¾¡ |
| [`Sklearn_AutoTune.py`](Sklearn_AutoTune.py) | å­¦ç¿’çµ‚äº†å¾Œã€Sklearn æ¤œè¨¼çµæœã‚’è‡ªå‹•å‡ºåŠ› (`final_results/sklearn/sklearn_validation_results.xlsx`) |

### ç‰¹å¾´é‡å¯„ä¸åˆ†æ

| ã‚¹ã‚¯ãƒªãƒ—ãƒˆ | æ©Ÿèƒ½ |
|------------|------|
| [`DNNç‰¹å¾è´¡çŒ®åˆ†æ.py`](DNNç‰¹å¾è´¡çŒ®åˆ†æ.py) | DNN ç‰¹å¾´é‡å¯„ä¸ã® SHAP GradientExplainer è§£æ |
| [`Sklearn_AutoTune.py`](Sklearn_AutoTune.py) | å­¦ç¿’çµ‚äº†å¾Œã€Sklearn ç‰¹å¾´é‡å¯„ä¸ã‚’è‡ªå‹•å‡ºåŠ› (`final_results/sklearn/sklearn_feature_importance.*`) |

### Y-Randomization æ¤œè¨¼

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: [`Y_Randomization.py`](Y_Randomization.py)

**æ©Ÿèƒ½**: Y-Scrambling æ¤œè¨¼ã€‚yå€¤ã‚’100å›ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã€QSAR ãƒ¢ãƒ‡ãƒ«ãŒç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®é–¢ä¿‚ã‚’çœŸã«å­¦ç¿’ã—ã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚çœŸã®ãƒ¢ãƒ‡ãƒ«ã® RÂ² ãŒãƒ©ãƒ³ãƒ€ãƒ ãƒ¢ãƒ‡ãƒ«ã®åˆ†å¸ƒã‚ˆã‚Šæœ‰æ„ã«é«˜ã‘ã‚Œã° (p < 0.05)ã€ãƒ¢ãƒ‡ãƒ«ã¯æœ‰åŠ¹ã§ã™ã€‚

**å‡ºåŠ›**: `final_results/sklearn/y_randomization.png`ã€`y_randomization.csv`

```bash
python Y_Randomization.py
```

### DNN Y-Randomization æ¤œè¨¼

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: [`DNN_Y_Randomization.py`](DNN_Y_Randomization.py)

**æ©Ÿèƒ½**: åŒä¸€ã® train/test åˆ†å‰²ã‚’å†åˆ©ç”¨ã—ãŸä¸Šã§ã€DNN ã® `y_train/y_val` ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦å†å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã—ã€çœŸã® DNN ã¨ãƒ©ãƒ³ãƒ€ãƒ åŒ– DNN ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ RÂ² åˆ†å¸ƒã¨ på€¤ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚

**å‡ºåŠ›**: `final_results/dnn/dnn_y_randomization.csv`ã€`dnn_y_randomization.png`ã€`dnn_y_randomization_summary.txt`

```bash
python DNN_Y_Randomization.py
```

### DNN ç·åˆæ¤œè¨¼ã¨ç‰¹å¾´é‡å¯„ä¸åˆ†æï¼ˆæœ€æ–° AutoTuneï¼‰

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: [`DNNç‰¹å¾è´¡çŒ®åˆ†æ.py`](DNNç‰¹å¾è´¡çŒ®åˆ†æ.py)

**æ©Ÿèƒ½**: `best_model.keras + best_model_preprocess.pkl` ã‚’å³å¯†ã«ä½¿ç”¨ã—ã€sklearn ã¨åŒæ§˜ã® 2Ã—2 DNN ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆå®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤ã€æ®‹å·®åˆ†å¸ƒã€æ®‹å·® vs äºˆæ¸¬å€¤ã€ç‰¹å¾´é‡å¯„ä¸ï¼‰ã¨ã€æ¤œè¨¼æ˜ç´°ãƒ»ç‰¹å¾´é‡å¯„ä¸ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

**å‡ºåŠ›**: `final_results/dnn/dnn_validation_plots.png`ã€`dnn_validation_results.csv`ã€`dnn_feature_importance.csv`

```bash
python DNNç‰¹å¾è´¡çŒ®åˆ†æ.py
```

> `Sklearn_æ¨¡å‹éªŒè¯.py` ã¨ `RFç‰¹å¾è´¡çŒ®åˆ†æ.py` ã¯ã€éå»ã®äº’æ›æ€§ã¨ãƒ‡ãƒãƒƒã‚°ã®ãŸã‚ã« `åºŸå¼ƒæ–‡ä»¶å­˜æ¡£/` ã«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚Œã¾ã—ãŸã€‚

---

## ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«èª¬æ˜

| ãƒ•ã‚¡ã‚¤ãƒ« | å ´æ‰€ | èª¬æ˜ | ç”Ÿæˆæ®µéš |
|----------|------|------|----------|
| `Huggins.xlsx` | ãƒ«ãƒ¼ãƒˆ | å…ƒãƒ‡ãƒ¼ã‚¿ | å…¥åŠ› |
| `43579_2022_237_MOESM1_ESM.csv` | `data/` | å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (1586ä»¶) | æ–°è¦å…¥åŠ› |
| `smiles_raw.csv` | `data/` | SMILES ç…§ä¼šçµæœ | Step 1 |
| `smiles_cleaned.xlsx` | `data/` | æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã® SMILES | æ‰‹å‹•å‡¦ç† |
| `huggins_preprocessed.xlsx` | `data/` | å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ (323ä»¶) | Step 2 |
| `merged_dataset.csv` | `data/` | çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (1893ä»¶) | Step 2.5 |
| `molecular_features.xlsx` | `data/` | 320æ¬¡å…ƒç‰¹å¾´é‡è¡Œåˆ— | Step 3 |
| `features_optimized.xlsx` | `data/` | é¸åˆ¥å¾Œç‰¹å¾´é‡ã‚µãƒ–ã‚»ãƒƒãƒˆ | Step 4 |
| `ga_selected_features.txt` | `results/` | GA é¸åˆ¥ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ | Step 4b |
| `ga_evolution_log.csv` | `results/` | GA é€²åŒ–ãƒ­ã‚° | Step 4b |
| `sklearn_model_bundle.pkl` | `results/` | Sklearn çµ±ä¸€ãƒ¢ãƒ‡ãƒ«ãƒãƒ³ãƒ‰ãƒ« | Step 5 |
| `best_model.keras` | `results/` | DNN AutoTune æœ€è‰¯ãƒ¢ãƒ‡ãƒ« | Step 5 |
| `train_test_split_indices.npz` | `results/` | çµ±ä¸€ train/test åˆ†å‰²ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | Step 4a |
| `sklearn_final_report.txt` | `final_results/sklearn/` | Sklearn æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ | Step 5d |
| `sklearn_validation_results.xlsx` | `final_results/sklearn/` | Sklearn æ¤œè¨¼çµæœæ˜ç´° | Step 5d |
| `sklearn_feature_importance.png` | `final_results/sklearn/` | Sklearn ç‰¹å¾´é‡å¯„ä¸å›³ | Step 5d |
| `sklearn_validation_plots.png` | `final_results/sklearn/` | Sklearn æ¤œè¨¼å¯è¦–åŒ– (4ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ) | Step 5d |
| `y_randomization.png` | `final_results/sklearn/` | Y-Randomization RÂ² åˆ†å¸ƒå›³ | Step 6 |
| `y_randomization.csv` | `final_results/sklearn/` | Y-Randomization è©³ç´°ãƒ‡ãƒ¼ã‚¿ | Step 6 |
| `dnn_validation_plots.png` | `final_results/dnn/` | DNN ç·åˆæ¤œè¨¼å›³ï¼ˆ4 ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆï¼‰ | Step 6 |
| `dnn_validation_results.csv` | `final_results/dnn/` | DNN ãƒ†ã‚¹ãƒˆäºˆæ¸¬ãƒ»æ®‹å·®æ˜ç´° | Step 6 |
| `dnn_feature_importance.csv` | `final_results/dnn/` | DNN ç‰¹å¾´é‡å¯„ä¸ï¼ˆSHAP/ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ | Step 6 |
| `dnn_y_randomization.png` | `final_results/dnn/` | DNN Y-Randomization RÂ² åˆ†å¸ƒå›³ | Step 6 |
| `dnn_y_randomization.csv` | `final_results/dnn/` | DNN Y-Randomization è©³ç´°ãƒ‡ãƒ¼ã‚¿ | Step 6 |
| `dnn_y_randomization_summary.txt` | `final_results/dnn/` | DNN Y-Randomization çµ±è¨ˆã‚µãƒãƒª | Step 6 |

---

## ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

> ä»¥ä¸‹ã¯ã€æœ¬å…¨ãƒ•ãƒ­ãƒ¼ï¼ˆGA â†’ RFECV â†’ AutoTuneï¼‰ã®çµæœã§ã™ï¼š1893 ã‚µãƒ³ãƒ—ãƒ«ã€æœ€çµ‚ 20 ç‰¹å¾´é‡ï¼ˆçµ±ä¸€ train/test åˆ†å‰²ï¼‰

| ãƒ¢ãƒ‡ãƒ« | CV Val RÂ² | Test RÂ² | Test MAE | Test RMSE |
|--------|-----------|---------|----------|-----------|
| **GradientBoosting** | **0.718** | **0.812** | **0.156** | **0.264** |
| XGBRegressor | 0.712 | 0.788 | 0.163 | 0.281 |
| RandomForest | 0.691 | 0.798 | 0.165 | 0.274 |
| MLPRegressor | 0.662 | 0.684 | 0.197 | 0.343 |
| DNN (AutoTune, best run) | â€” | 0.786 | 0.181 | 0.282 |

> â„¹ï¸ ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¯åŒä¸€ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§è©•ä¾¡ã•ã‚Œã¦ãŠã‚Šã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¯ç‰¹å¾´é‡é¸æŠã‚„ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ã¯ä¸€åˆ‡é–¢ä¸ã—ã¦ã„ã¾ã›ã‚“ã€‚
> â„¹ï¸ DNN è¡Œã¯ã€AutoTune æœ€é©ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®8å›å†å­¦ç¿’ã®ã†ã¡æœ€è‰¯ã®å›ã®çµæœã§ã™ï¼ˆCV å¹³å‡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚

---

## ä»£è¡¨çš„ãªå‡ºåŠ›å›³

### Sklearn: ç‰¹å¾´é‡å¯„ä¸

![Sklearn Feature Importance](../final_results/sklearn/sklearn_feature_importance.png)

### Sklearn: æ¤œè¨¼å¯è¦–åŒ–ï¼ˆ4 ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆï¼‰

![Sklearn Validation Plots](../final_results/sklearn/sklearn_validation_plots.png)

### Sklearn: Y-Randomization åˆ†å¸ƒ

![Sklearn Y-Randomization](../final_results/sklearn/y_randomization.png)

### DNN: Y-Randomization åˆ†å¸ƒ

![DNN Y-Randomization](../final_results/dnn/dnn_y_randomization.png)

### DNN: ç·åˆæ¤œè¨¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆ4 ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆï¼‰

![DNN Validation Plots](../final_results/dnn/dnn_validation_plots.png)

---

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

```bash
# 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/Nothingness-Void/Graduation-project
cd Graduation-project

# 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
conda install -c conda-forge rdkit

# 3. ãƒ‡ãƒ¼ã‚¿çµ±åˆ + ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° + äºŒæ®µéšç‰¹å¾´é‡é¸æŠ + ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
python åˆå¹¶æ•°æ®é›†.py              # æ—§ãƒ‡ãƒ¼ã‚¿ã¨æ–°ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ
python ç‰¹å¾å·¥ç¨‹.py                # å…¨é‡ RDKit è¨˜è¿°å­ (320æ¬¡å…ƒ)
python é—ä¼ .py                   # GA ç²—é¸åˆ¥ (320 â†’ ~20-40, ç´„ 20-40 åˆ†)
python ç‰¹å¾ç­›é€‰.py                # RFECV ç²¾é¸åˆ¥ (~20-40 â†’ ~8-15)
python Sklearn_AutoTune.py       # Sklearn è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
python DNN_AutoTune.py           # DNN Hyperband è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
python Y_Randomization.py        # Sklearn Y-Randomization æ¤œè¨¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
python DNN_Y_Randomization.py    # DNN Y-Randomization æ¤œè¨¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

# ã¾ãŸã¯: data/molecular_features.xlsx ãŒæ—¢ã«ã‚ã‚‹å ´åˆã€Step 4 ã‹ã‚‰é–‹å§‹
python é—ä¼ .py
python Sklearn_AutoTune.py
python DNN_AutoTune.py
```

---

## è©•ä¾¡æŒ‡æ¨™

| æŒ‡æ¨™ | å¼ | èª¬æ˜ |
|------|----|------|
| **RÂ²** | 1 - SS_res/SS_tot | æ±ºå®šä¿‚æ•°ã€‚1ã«è¿‘ã„ã»ã©è‰¯ã„ |
| **MAE** | mean(\|y_true - y_pred\|) | å¹³å‡çµ¶å¯¾èª¤å·® |
| **RMSE** | âˆš(mean((y_true - y_pred)Â²)) | äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·® |

---

## License

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å’æ¥­è¨­è¨ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚Šã€å­¦è¡“ç ”ç©¶ç›®çš„ã§ã®ã¿ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
